{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Optional, Union, Tuple\n",
    "from pathlib import Path\n",
    "import positional_encoder as pe\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(dim1: int, dim2: int, device: Optional[torch.device] = None) -> Tensor:\n",
    "    \"\"\"\n",
    "    Generates an upper-triangular matrix of -inf, with zeros on diag.\n",
    "    Modified from: \n",
    "    https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "\n",
    "    Args:\n",
    "        dim1: int, for both src and tgt masking, this must be target sequence\n",
    "              length\n",
    "        dim2: int, for src masking this must be encoder sequence length (i.e. \n",
    "              the length of the input sequence to the model), \n",
    "              and for tgt masking, this must be target sequence length \n",
    "        device: (optional) torch.device on which to create the mask\n",
    "\n",
    "    Returns:\n",
    "        A Tensor of shape [dim1, dim2]\n",
    "    \"\"\"\n",
    "    mask = torch.triu(torch.ones(dim1, dim2) * float('-inf'), diagonal=1)\n",
    "    if device is not None:\n",
    "        mask = mask.to(device)\n",
    "    return mask\n",
    "\n",
    "\n",
    "\n",
    "def get_indices_input_target(num_obs, input_len, step_size, forecast_horizon, target_len):\n",
    "        \"\"\"\n",
    "        Produce all the start and end index positions of all sub-sequences.\n",
    "        The indices will be used to split the data into sub-sequences on which \n",
    "        the models will be trained. \n",
    "\n",
    "        Returns a tuple with four elements:\n",
    "        1) The index position of the first element to be included in the input sequence\n",
    "        2) The index position of the last element to be included in the input sequence\n",
    "        3) The index position of the first element to be included in the target sequence\n",
    "        4) The index position of the last element to be included in the target sequence\n",
    "\n",
    "        \n",
    "        Args:\n",
    "            num_obs (int): Number of observations in the entire dataset for which\n",
    "                            indices must be generated.\n",
    "\n",
    "            input_len (int): Length of the input sequence (a sub-sequence of \n",
    "                             of the entire data sequence)\n",
    "\n",
    "            step_size (int): Size of each step as the data sequence is traversed.\n",
    "                             If 1, the first sub-sequence will be indices 0-input_len, \n",
    "                             and the next will be 1-input_len.\n",
    "\n",
    "            forecast_horizon (int): How many index positions is the target away from\n",
    "                                    the last index position of the input sequence?\n",
    "                                    If forecast_horizon=1, and the input sequence\n",
    "                                    is data[0:10], the target will be data[11:taget_len].\n",
    "\n",
    "            target_len (int): Length of the target / output sequence.\n",
    "        \"\"\"\n",
    "\n",
    "        input_len = round(input_len) # just a precaution\n",
    "        start_position = 0\n",
    "        stop_position = num_obs-1 # because of 0 indexing\n",
    "        \n",
    "        subseq_first_idx = start_position\n",
    "        subseq_last_idx = start_position + input_len\n",
    "        target_first_idx = subseq_last_idx + forecast_horizon\n",
    "        target_last_idx = target_first_idx + target_len \n",
    "        print(\"target_last_idx is {}\".format(target_last_idx))\n",
    "        print(\"stop_position is {}\".format(stop_position))\n",
    "        indices = []\n",
    "        while target_last_idx <= stop_position:\n",
    "            indices.append((subseq_first_idx, subseq_last_idx, target_first_idx, target_last_idx))\n",
    "            subseq_first_idx += step_size\n",
    "            subseq_last_idx += step_size\n",
    "            target_first_idx = subseq_last_idx + forecast_horizon\n",
    "            target_last_idx = target_first_idx + target_len\n",
    "\n",
    "        return indices\n",
    "\n",
    "def get_indices_entire_sequence(data: pd.DataFrame, window_size: int, step_size: int) -> list:\n",
    "        \"\"\"\n",
    "        Produce all the start and end index positions that is needed to produce\n",
    "        the sub-sequences. \n",
    "\n",
    "        Returns a list of tuples. Each tuple is (start_idx, end_idx) of a sub-\n",
    "        sequence. These tuples should be used to slice the dataset into sub-\n",
    "        sequences. These sub-sequences should then be passed into a function\n",
    "        that slices them into input and target sequences. \n",
    "        \n",
    "        Args:\n",
    "            num_obs (int): Number of observations (time steps) in the entire \n",
    "                           dataset for which indices must be generated, e.g. \n",
    "                           len(data)\n",
    "\n",
    "            window_size (int): The desired length of each sub-sequence. Should be\n",
    "                               (input_sequence_length + target_sequence_length)\n",
    "                               E.g. if you want the model to consider the past 100\n",
    "                               time steps in order to predict the future 50 \n",
    "                               time steps, window_size = 100+50 = 150\n",
    "\n",
    "            step_size (int): Size of each step as the data sequence is traversed \n",
    "                             by the moving window.\n",
    "                             If 1, the first sub-sequence will be [0:window_size], \n",
    "                             and the next will be [1:window_size].\n",
    "\n",
    "        Return:\n",
    "            indices: a list of tuples\n",
    "        \"\"\"\n",
    "\n",
    "        stop_position = len(data)-1 # 1- because of 0 indexing\n",
    "        \n",
    "        # Start the first sub-sequence at index position 0\n",
    "        subseq_first_idx = 0\n",
    "        \n",
    "        subseq_last_idx = window_size\n",
    "        \n",
    "        indices = []\n",
    "        \n",
    "        while subseq_last_idx <= stop_position:\n",
    "\n",
    "            indices.append((subseq_first_idx, subseq_last_idx))\n",
    "            \n",
    "            subseq_first_idx += step_size\n",
    "            \n",
    "            subseq_last_idx += step_size\n",
    "\n",
    "        return indices\n",
    "\n",
    "\n",
    "def read_data(data_dir: Union[str, Path] = \"data\",  \n",
    "    timestamp_col_name: str=\"timestamp\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read data from csv file and return pd.Dataframe object\n",
    "\n",
    "    Args:\n",
    "\n",
    "        data_dir: str or Path object specifying the path to the directory \n",
    "                  containing the data\n",
    "\n",
    "        target_col_name: str, the name of the column containing the target variable\n",
    "\n",
    "        timestamp_col_name: str, the name of the column or named index \n",
    "                            containing the timestamps\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure that `data_dir` is a Path object\n",
    "    data_dir = Path(data_dir)\n",
    "    \n",
    "    # Read csv file\n",
    "    npy_files = list(data_dir.glob(\"*.npy\"))\n",
    "    \n",
    "    if len(npy_files) > 1:\n",
    "        raise ValueError(\"data_dir contains more than 1 csv file. Must only contain 1\")\n",
    "    elif len(npy_files) == 0:\n",
    "        raise ValueError(\"data_dir must contain at least 1 csv file.\")\n",
    "\n",
    "    data_path = npy_files[0]\n",
    "\n",
    "    print(\"Reading file in {}\".format(data_path))\n",
    "\n",
    "    data = np.load(data_path, allow_pickle=True).item()\n",
    "    data = pd.DataFrame(data)\n",
    "\n",
    "    # Make sure all \"n/e\" values have been removed from df. \n",
    "    if is_ne_in_df(data):\n",
    "        raise ValueError(\"data frame contains 'n/e' values. These must be handled\")\n",
    "\n",
    "    data = to_numeric_and_downcast_data(data)\n",
    "\n",
    "    # Make sure data is in ascending order by timestamp\n",
    "    data.sort_values(by=[timestamp_col_name], inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "def is_ne_in_df(df:pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Some raw data files contain cells with \"n/e\". This function checks whether\n",
    "    any column in a df contains a cell with \"n/e\". Returns False if no columns\n",
    "    contain \"n/e\", True otherwise\n",
    "    \"\"\"\n",
    "    \n",
    "    for col in df.columns:\n",
    "\n",
    "        true_bool = (df[col] == \"n/e\")\n",
    "\n",
    "        if any(true_bool):\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def to_numeric_and_downcast_data(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Downcast columns in df to smallest possible version of it's existing data\n",
    "    type\n",
    "    \"\"\"\n",
    "    fcols = df.select_dtypes('float').columns\n",
    "    \n",
    "    icols = df.select_dtypes('integer').columns\n",
    "\n",
    "    df[fcols] = df[fcols].apply(pd.to_numeric, downcast='float')\n",
    "    \n",
    "    df[icols] = df[icols].apply(pd.to_numeric, downcast='integer')\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class used for transformer models.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "        data: torch.tensor,\n",
    "        indices: list, \n",
    "        enc_seq_len: int, \n",
    "        dec_seq_len: int, \n",
    "        target_seq_len: int\n",
    "        ) -> None:\n",
    "\n",
    "        \"\"\"\n",
    "        Args:\n",
    "\n",
    "            data: tensor, the entire train, validation or test data sequence \n",
    "                        before any slicing. If univariate, data.size() will be \n",
    "                        [number of samples, number of variables]\n",
    "                        where the number of variables will be equal to 1 + the number of\n",
    "                        exogenous variables. Number of exogenous variables would be 0\n",
    "                        if univariate.\n",
    "\n",
    "            indices: a list of tuples. Each tuple has two elements:\n",
    "                     1) the start index of a sub-sequence\n",
    "                     2) the end index of a sub-sequence. \n",
    "                     The sub-sequence is split into src, trg and trg_y later.  \n",
    "\n",
    "            enc_seq_len: int, the desired length of the input sequence given to the\n",
    "                     the first layer of the transformer model.\n",
    "\n",
    "            target_seq_len: int, the desired length of the target sequence (the output of the model)\n",
    "\n",
    "            target_idx: The index position of the target variable in data. Data\n",
    "                        is a 2D tensor\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.indices = indices\n",
    "\n",
    "        self.data = data\n",
    "\n",
    "        print(\"From get_src_trg: data size = {}\".format(data.size()))\n",
    "\n",
    "        self.enc_seq_len = enc_seq_len\n",
    "\n",
    "        self.dec_seq_len = dec_seq_len\n",
    "\n",
    "        self.target_seq_len = target_seq_len\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Returns a tuple with 3 elements:\n",
    "        1) src (the encoder input)\n",
    "        2) trg (the decoder input)\n",
    "        3) trg_y (the target)\n",
    "        \"\"\"\n",
    "        # Get the first element of the i'th tuple in the list self.indicesasdfas\n",
    "        start_idx = self.indices[index][0]\n",
    "\n",
    "        # Get the second (and last) element of the i'th tuple in the list self.indices\n",
    "        end_idx = self.indices[index][1]\n",
    "\n",
    "        sequence = self.data[start_idx:end_idx]\n",
    "\n",
    "        #print(\"From __getitem__: sequence length = {}\".format(len(sequence)))\n",
    "\n",
    "        src, trg, trg_y = self.get_src_trg(\n",
    "            sequence=sequence,\n",
    "            enc_seq_len=self.enc_seq_len,\n",
    "            dec_seq_len=self.dec_seq_len,\n",
    "            target_seq_len=self.target_seq_len\n",
    "            )\n",
    "\n",
    "        return src, trg, trg_y\n",
    "    \n",
    "    def get_src_trg(\n",
    "        self,\n",
    "        sequence: torch.Tensor, \n",
    "        enc_seq_len: int, \n",
    "        dec_seq_len: int, \n",
    "        target_seq_len: int\n",
    "        ) -> Tuple[torch.tensor, torch.tensor, torch.tensor]:\n",
    "\n",
    "        \"\"\"\n",
    "        Generate the src (encoder input), trg (decoder input) and trg_y (the target)\n",
    "        sequences from a sequence. \n",
    "\n",
    "        Args:\n",
    "\n",
    "            sequence: tensor, a 1D tensor of length n where \n",
    "                    n = encoder input length + target sequence length  \n",
    "\n",
    "            enc_seq_len: int, the desired length of the input to the transformer encoder\n",
    "\n",
    "            target_seq_len: int, the desired length of the target sequence (the \n",
    "                            one against which the model output is compared)\n",
    "\n",
    "        Return: \n",
    "\n",
    "            src: tensor, 1D, used as input to the transformer model\n",
    "\n",
    "            trg: tensor, 1D, used as input to the transformer model\n",
    "\n",
    "            trg_y: tensor, 1D, the target sequence against which the model output\n",
    "                is compared when computing loss. \n",
    "        \n",
    "        \"\"\"\n",
    "        assert len(sequence) == enc_seq_len + target_seq_len, \"Sequence length does not equal (input length + target length)\"\n",
    "        \n",
    "        # encoder input\n",
    "        src = sequence[:enc_seq_len] \n",
    "        \n",
    "        # decoder input. As per the paper, it must have the same dimension as the \n",
    "        # target sequence, and it must contain the last value of src, and all\n",
    "        # values of trg_y except the last (i.e. it must be shifted right by 1)\n",
    "        trg = sequence[enc_seq_len-1:len(sequence)-1]\n",
    "        \n",
    "        assert len(trg) == target_seq_len, \"Length of trg does not match target sequence length\"\n",
    "\n",
    "        # The target sequence against which the model output will be compared to compute loss\n",
    "        trg_y = sequence[-target_seq_len:]\n",
    "\n",
    "        assert len(trg_y) == target_seq_len, \"Length of trg_y does not match target sequence length\"\n",
    "\n",
    "        return src, trg, trg_y.squeeze(-1) # change size from [batch_size, target_seq_len, num_features] to [batch_size, target_seq_len] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positional Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PositionalEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    The authors of the original transformer paper describe very succinctly what \n",
    "    the positional encoding layer does and why it is needed:\n",
    "    \n",
    "    \"Since our model contains no recurrence and no convolution, in order for the \n",
    "    model to make use of the order of the sequence, we must inject some \n",
    "    information about the relative or absolute position of the tokens in the \n",
    "    sequence.\" (Vaswani et al, 2017)\n",
    "    Adapted from: \n",
    "    https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        dropout: float=0.1, \n",
    "        max_seq_len: int=5000, \n",
    "        d_model: int=512,\n",
    "        batch_first: bool=False\n",
    "        ):\n",
    "\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            dropout: the dropout rate\n",
    "            max_seq_len: the maximum length of the input sequences\n",
    "            d_model: The dimension of the output of sub-layers in the model \n",
    "                     (Vaswani et al, 2017)\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "        # adapted from PyTorch tutorial\n",
    "        position = torch.arange(max_seq_len).unsqueeze(1)\n",
    "        \n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        \n",
    "        if self.batch_first:\n",
    "            pe = torch.zeros(1, max_seq_len, d_model)\n",
    "            \n",
    "            pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "            \n",
    "            pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        else:\n",
    "            pe = torch.zeros(max_seq_len, 1, d_model)\n",
    "        \n",
    "            pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        \n",
    "            pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, enc_seq_len, dim_val] or \n",
    "               [enc_seq_len, batch_size, dim_val]\n",
    "        \"\"\"\n",
    "        if self.batch_first:\n",
    "            x = x + self.pe[:,:x.size(1)]\n",
    "        else:\n",
    "            x = x + self.pe[:x.size(0)]\n",
    "\n",
    "        return self.dropout(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_encoder_decoder_inference(\n",
    "    model: nn.Module, \n",
    "    src: torch.Tensor, \n",
    "    forecast_window: int,\n",
    "    batch_size: int,\n",
    "    device,\n",
    "    batch_first: bool=False\n",
    "    ) -> torch.Tensor:\n",
    "\n",
    "    \"\"\"\n",
    "    NB! This function is currently only tested on models that work with \n",
    "    batch_first = False\n",
    "    \n",
    "    This function is for encoder-decoder type models in which the decoder requires\n",
    "    an input, tgt, which - during training - is the target sequence. During inference,\n",
    "    the values of tgt are unknown, and the values therefore have to be generated\n",
    "    iteratively.  \n",
    "    \n",
    "    This function returns a prediction of length forecast_window for each batch in src\n",
    "    \n",
    "    NB! If you want the inference to be done without gradient calculation, \n",
    "    make sure to call this function inside the context manager torch.no_grad like:\n",
    "    with torch.no_grad:\n",
    "        run_encoder_decoder_inference()\n",
    "        \n",
    "    The context manager is intentionally not called inside this function to make\n",
    "    it usable in cases where the function is used to compute loss that must be \n",
    "    backpropagated during training and gradient calculation hence is required.\n",
    "    \n",
    "    If use_predicted_tgt = True:\n",
    "    To begin with, tgt is equal to the last value of src. Then, the last element\n",
    "    in the model's prediction is iteratively concatenated with tgt, such that \n",
    "    at each step in the for-loop, tgt's size increases by 1. Finally, tgt will\n",
    "    have the correct length (target sequence length) and the final prediction\n",
    "    will be produced and returned.\n",
    "    \n",
    "    Args:\n",
    "        model: An encoder-decoder type model where the decoder requires\n",
    "               target values as input. Should be set to evaluation mode before \n",
    "               passed to this function.\n",
    "               \n",
    "        src: The input to the model\n",
    "        \n",
    "        forecast_horizon: The desired length of the model's output, e.g. 58 if you\n",
    "                         want to predict the next 58 hours of FCR prices.\n",
    "                           \n",
    "        batch_size: batch size\n",
    "        \n",
    "        batch_first: If true, the shape of the model input should be \n",
    "                     [batch size, input sequence length, number of features].\n",
    "                     If false, [input sequence length, batch size, number of features]\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Dimension of a batched model input that contains the target sequence values\n",
    "    target_seq_dim = 0 if batch_first == False else 1\n",
    "\n",
    "    # Take the last value of thetarget variable in all batches in src and make it tgt\n",
    "    # as per the Influenza paper\n",
    "    tgt = src[-1, :, 0] if batch_first == False else src[:, -1, 0] # shape [1, batch_size, 1]\n",
    "\n",
    "    # Change shape from [batch_size] to [1, batch_size, 1]\n",
    "    if batch_size == 1 and batch_first == False:\n",
    "        tgt = tgt.unsqueeze(0).unsqueeze(0) # change from [1] to [1, 1, 1]\n",
    "\n",
    "    # Change shape from [batch_size] to [1, batch_size, 1]\n",
    "    if batch_first == False and batch_size > 1:\n",
    "        tgt = tgt.unsqueeze(0).unsqueeze(-1)\n",
    "\n",
    "    # Iteratively concatenate tgt with the first element in the prediction\n",
    "    for _ in range(forecast_window-1):\n",
    "\n",
    "        # Create masks\n",
    "        dim_a = tgt.shape[1] if batch_first == True else tgt.shape[0]\n",
    "\n",
    "        dim_b = src.shape[1] if batch_first == True else src.shape[0]\n",
    "\n",
    "        tgt_mask = generate_square_subsequent_mask(\n",
    "            dim1=dim_a,\n",
    "            dim2=dim_a,\n",
    "            device=device\n",
    "            )\n",
    "\n",
    "        src_mask = generate_square_subsequent_mask(\n",
    "            dim1=dim_a,\n",
    "            dim2=dim_b,\n",
    "            device=device\n",
    "            )\n",
    "\n",
    "        # Make prediction\n",
    "        prediction = model(src, tgt, src_mask, tgt_mask) \n",
    "\n",
    "        # If statement simply makes sure that the predicted value is \n",
    "        # extracted and reshaped correctly\n",
    "        if batch_first == False:\n",
    "\n",
    "            # Obtain the predicted value at t+1 where t is the last time step \n",
    "            # represented in tgt\n",
    "            last_predicted_value = prediction[-1, :, :] \n",
    "\n",
    "            # Reshape from [batch_size, 1] --> [1, batch_size, 1]\n",
    "            last_predicted_value = last_predicted_value.unsqueeze(0)\n",
    "\n",
    "        else:\n",
    "\n",
    "            # Obtain predicted value\n",
    "            last_predicted_value = prediction[:, -1, :]\n",
    "\n",
    "            # Reshape from [batch_size, 1] --> [batch_size, 1, 1]\n",
    "            last_predicted_value = last_predicted_value.unsqueeze(-1)\n",
    "\n",
    "        # Detach the predicted element from the graph and concatenate with \n",
    "        # tgt in dimension 1 or 0\n",
    "        tgt = torch.cat((tgt, last_predicted_value.detach()), target_seq_dim)\n",
    "    \n",
    "    # Create masks\n",
    "    dim_a = tgt.shape[1] if batch_first == True else tgt.shape[0]\n",
    "\n",
    "    dim_b = src.shape[1] if batch_first == True else src.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(\n",
    "        dim1=dim_a,\n",
    "        dim2=dim_a,\n",
    "        device=device\n",
    "        )\n",
    "\n",
    "    src_mask = generate_square_subsequent_mask(\n",
    "        dim1=dim_a,\n",
    "        dim2=dim_b,\n",
    "        device=device\n",
    "        )\n",
    "\n",
    "    # Make final prediction\n",
    "    final_prediction = model(src, tgt, src_mask, tgt_mask)\n",
    "\n",
    "    return final_prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesTransformer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_size: int,\n",
    "                 dec_seq_len: int,\n",
    "                 batch_first: bool = True,\n",
    "                 out_seq_len: int = 58,\n",
    "                 dim_val: int = 512,  \n",
    "                 n_encoder_layers: int = 4,\n",
    "                 n_decoder_layers: int = 4,\n",
    "                 n_heads: int = 8,\n",
    "                 dropout_encoder: float = 0.2, \n",
    "                 dropout_decoder: float = 0.2,\n",
    "                 dropout_pos_enc: float = 0.1,\n",
    "                 dim_feedforward_encoder: int = 2048,\n",
    "                 dim_feedforward_decoder: int = 2048,\n",
    "                 num_predicted_features: int = 1,\n",
    "                 verbose: bool = False):\n",
    "\n",
    "        super().__init__()\n",
    "        self.dec_seq_len = dec_seq_len\n",
    "        self.verbose = verbose  # Enable debug printing\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Initializing Transformer: input_size={input_size}, num_predicted_features={num_predicted_features}\")\n",
    "\n",
    "        # Input layers\n",
    "        self.encoder_input_layer = nn.Linear(input_size, dim_val)\n",
    "        self.decoder_input_layer = nn.Linear(num_predicted_features, dim_val)\n",
    "\n",
    "        # Positional Encoding\n",
    "        self.positional_encoding_layer = pe.PositionalEncoder(d_model=dim_val, dropout=dropout_pos_enc)\n",
    "\n",
    "        # Transformer Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=dim_val, nhead=n_heads,\n",
    "                                                   dim_feedforward=dim_feedforward_encoder,\n",
    "                                                   dropout=dropout_encoder, batch_first=batch_first)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_encoder_layers)\n",
    "\n",
    "        # Transformer Decoder\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model=dim_val, nhead=n_heads,\n",
    "                                                   dim_feedforward=dim_feedforward_decoder,\n",
    "                                                   dropout=dropout_decoder, batch_first=batch_first)\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=n_decoder_layers)\n",
    "\n",
    "        # Output layer\n",
    "        self.linear_mapping = nn.Linear(dim_val, num_predicted_features)\n",
    "\n",
    "    def forward(self, src: torch.Tensor, tgt: torch.Tensor, src_mask: torch.Tensor = None, \n",
    "                tgt_mask: torch.Tensor = None) -> torch.Tensor:\n",
    "        \n",
    "        # Debug: Print shapes if verbose mode is enabled\n",
    "        if self.verbose:\n",
    "            print(f\"src shape: {src.shape}, expected last dim: {self.encoder_input_layer.in_features}\")\n",
    "            print(f\"tgt shape: {tgt.shape}, expected last dim: {self.decoder_input_layer.in_features}\")\n",
    "\n",
    "        # Validate input dimensions\n",
    "        assert src.shape[-1] == self.encoder_input_layer.in_features, \\\n",
    "            f\"src last dim ({src.shape[-1]}) must match input_size ({self.encoder_input_layer.in_features})\"\n",
    "        assert tgt.shape[-1] == self.decoder_input_layer.in_features, \\\n",
    "            f\"tgt last dim ({tgt.shape[-1]}) must match num_predicted_features ({self.decoder_input_layer.in_features})\"\n",
    "\n",
    "        # Encoding\n",
    "        src = self.encoder_input_layer(src)\n",
    "        src = self.positional_encoding_layer(src)\n",
    "        src = self.encoder(src)\n",
    "\n",
    "        # Decoding\n",
    "        decoder_output = self.decoder_input_layer(tgt)\n",
    "        decoder_output = self.decoder(decoder_output, memory=src, tgt_mask=tgt_mask, memory_mask=src_mask)\n",
    "\n",
    "        # Output mapping\n",
    "        decoder_output = self.linear_mapping(decoder_output)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"Output shape: {decoder_output.shape}, expected last dim: {self.linear_mapping.out_features}\")\n",
    "\n",
    "        return decoder_output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Hyperparameter combinations:\n",
      "batch_size=128, forecast_window=2, enc_seq_len=6, window_size=8\n",
      "batch_size=128, forecast_window=2, enc_seq_len=7, window_size=9\n",
      "batch_size=128, forecast_window=3, enc_seq_len=6, window_size=9\n",
      "batch_size=128, forecast_window=3, enc_seq_len=7, window_size=10\n",
      "\n",
      "Processing file: lorenz63_on0.05_train.npy\n",
      "\n",
      "======================================\n",
      "Training with: batch_size=128, forecast_window=2, enc_seq_len=6, window_size=8\n",
      "From get_src_trg: data size = torch.Size([100000, 3])\n",
      "DataLoader size: 156\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 108\u001b[0m\n\u001b[0;32m    106\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    107\u001b[0m epoch_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 108\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m src, tgt, tgt_y \u001b[38;5;129;01min\u001b[39;00m training_dataloader:\n\u001b[0;32m    109\u001b[0m     src \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    110\u001b[0m     tgt \u001b[38;5;241m=\u001b[39m tgt\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn [4], line 75\u001b[0m, in \u001b[0;36mTransformerDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     71\u001b[0m sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[start_idx:end_idx]\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m#print(\"From __getitem__: sequence length = {}\".format(len(sequence)))\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m src, trg, trg_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_src_trg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43msequence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msequence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43menc_seq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menc_seq_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdec_seq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdec_seq_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_seq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_seq_len\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m src, trg, trg_y\n",
      "Cell \u001b[1;32mIn [4], line 133\u001b[0m, in \u001b[0;36mTransformerDataset.get_src_trg\u001b[1;34m(self, sequence, enc_seq_len, dec_seq_len, target_seq_len)\u001b[0m\n\u001b[0;32m    129\u001b[0m trg_y \u001b[38;5;241m=\u001b[39m sequence[\u001b[38;5;241m-\u001b[39mtarget_seq_len:]\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trg_y) \u001b[38;5;241m==\u001b[39m target_seq_len, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of trg_y does not match target sequence length\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m src, trg, \u001b[43mtrg_y\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ----- Hyperparameter Grid -----\n",
    "# You can adjust these lists.\n",
    "batch_sizes      = [128]\n",
    "forecast_windows = [2, 3]\n",
    "enc_seq_lens     = [6, 7]\n",
    "\n",
    "# Instead of a separate window_sizes list, compute window_size = enc_seq_len + forecast_window.\n",
    "hyperparameter_grid = [\n",
    "    (batch_size, forecast_window, enc_seq_len, enc_seq_len + forecast_window)\n",
    "    for batch_size in batch_sizes\n",
    "    for forecast_window in forecast_windows\n",
    "    for enc_seq_len in enc_seq_lens\n",
    "]\n",
    "\n",
    "# ----- Fixed Parameters -----\n",
    "step_size       = 5\n",
    "epochs          = 2    # Increase epochs for a more robust comparison if needed\n",
    "batch_first     = True\n",
    "target_col_name = 'x'\n",
    "timestamp_col   = \"t\"\n",
    "exogenous_vars  = ['y', 'z']\n",
    "input_variables = [target_col_name] + exogenous_vars\n",
    "\n",
    "# Directory containing the training data (.npy files)\n",
    "data_dir = r\"C:\\Users\\hecht\\OneDrive - Universität Heidelberg\\Dokumente\\_Studium\\_Master\\_2. Semester\\DSML\\Final Project\\DSML_Final_Project\\Traindata\"\n",
    "\n",
    "# Device (use GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Dictionaries to store results per dataset file\n",
    "# Each file's results: list of tuples (hyperparams, combined_loss_curve, final_error)\n",
    "results_by_file = {}\n",
    "\n",
    "# Also store best hyperparameter combination per file\n",
    "best_results_by_file = {}\n",
    "\n",
    "# ----- Print Hyperparameter Combinations -----\n",
    "print(\"Hyperparameter combinations:\")\n",
    "for hp in hyperparameter_grid:\n",
    "    batch_size, forecast_window, enc_seq_len, window_size = hp\n",
    "    print(f\"batch_size={batch_size}, forecast_window={forecast_window}, enc_seq_len={enc_seq_len}, window_size={window_size}\")\n",
    "\n",
    "# ----- Process each .npy file separately -----\n",
    "for file_name in os.listdir(data_dir):\n",
    "    if not file_name.endswith('.npy'):\n",
    "        continue\n",
    "\n",
    "    file_path = os.path.join(data_dir, file_name)\n",
    "    data = np.load(file_path)\n",
    "    print(f\"\\nProcessing file: {file_name}\")\n",
    "    \n",
    "    # Get input size based on number of columns in the data\n",
    "    input_size = data.shape[1]\n",
    "    \n",
    "    # Initialize a list to hold loss curves and final errors for each hyperparameter combination\n",
    "    results_by_file[file_name] = []\n",
    "    best_error = float('inf')\n",
    "    best_hyperparams = None\n",
    "    best_loss_curve = None\n",
    "\n",
    "    # Iterate through each hyperparameter combination\n",
    "    for batch_size, forecast_window, enc_seq_len, window_size in hyperparameter_grid:\n",
    "        print(\"\\n======================================\")\n",
    "        print(f\"Training with: batch_size={batch_size}, forecast_window={forecast_window}, enc_seq_len={enc_seq_len}, window_size={window_size}\")\n",
    "        \n",
    "        # Get training indices for this dataset and hyperparameter setting.\n",
    "        training_indices = get_indices_entire_sequence(data, window_size, step_size)\n",
    "        if len(training_indices) == 0:\n",
    "            print(f\"No valid training indices found in {file_name} for window_size={window_size}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Create Dataset and DataLoader.\n",
    "        training_data = TransformerDataset(\n",
    "            data=torch.tensor(data).float(),\n",
    "            indices=training_indices,\n",
    "            enc_seq_len=enc_seq_len,\n",
    "            dec_seq_len=forecast_window,\n",
    "            target_seq_len=forecast_window\n",
    "        )\n",
    "        training_dataloader = DataLoader(training_data, batch_size=batch_size, drop_last=True)\n",
    "        print(f\"DataLoader size: {len(training_dataloader)}\")\n",
    "        \n",
    "        # Initialize the model.\n",
    "        model = TimeSeriesTransformer(\n",
    "            input_size=input_size,\n",
    "            dec_seq_len=forecast_window,\n",
    "            batch_first=batch_first,\n",
    "            num_predicted_features=input_size\n",
    "        ).to(device)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "        criterion = torch.nn.MSELoss()\n",
    "        \n",
    "        combined_loss_curve = []  # Stores the loss for every batch during training\n",
    "        \n",
    "        # Training loop for this hyperparameter setting.\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            epoch_losses = []\n",
    "            for src, tgt, tgt_y in training_dataloader:\n",
    "                src = src.to(device)\n",
    "                tgt = tgt.to(device)\n",
    "                tgt_y = tgt_y.to(device)\n",
    "                \n",
    "                # Create masks. For the decoder self-attention, the mask is square.\n",
    "                # (Adjust mask_enc if needed for your model.)\n",
    "                mask_enc = generate_square_subsequent_mask(forecast_window, enc_seq_len).to(device)\n",
    "                mask_dec = generate_square_subsequent_mask(forecast_window, forecast_window).to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                prediction = model(src, tgt, mask_enc, mask_dec)\n",
    "                loss = criterion(tgt_y, prediction)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                epoch_losses.append(loss.item())\n",
    "                combined_loss_curve.append(loss.item())\n",
    "            \n",
    "            # Print overall progress after each epoch\n",
    "            avg_epoch_loss = sum(epoch_losses) / len(epoch_losses) if epoch_losses else float('inf')\n",
    "            print(f\"Epoch {epoch+1}/{epochs} completed. Average loss: {avg_epoch_loss:.4f}\")\n",
    "        \n",
    "        # After training for this hyperparameter setting, use the last batch loss as the representative final error.\n",
    "        if combined_loss_curve:\n",
    "            final_error = combined_loss_curve[-1]\n",
    "            print(f\"Final error (last batch loss) for this combination: {final_error:.4f}\")\n",
    "            \n",
    "            # Store the results for this hyperparameter combination.\n",
    "            results_by_file[file_name].append(((batch_size, forecast_window, enc_seq_len, window_size), combined_loss_curve, final_error))\n",
    "            \n",
    "            # Check if this is the best hyperparameter combination for this file so far.\n",
    "            if final_error < best_error:\n",
    "                best_error = final_error\n",
    "                best_hyperparams = {\n",
    "                    'batch_size': batch_size,\n",
    "                    'forecast_window': forecast_window,\n",
    "                    'enc_seq_len': enc_seq_len,\n",
    "                    'window_size': window_size\n",
    "                }\n",
    "                best_loss_curve = combined_loss_curve\n",
    "    \n",
    "    # Save the best results for this file.\n",
    "    best_results_by_file[file_name] = (best_hyperparams, best_error, best_loss_curve)\n",
    "\n",
    "# ----- After Training: Print Overview and Plot Subplots -----\n",
    "print(\"\\n======================================\")\n",
    "print(\"Final losses for each hyperparameter combination per file:\")\n",
    "for file_name, results in results_by_file.items():\n",
    "    print(f\"\\nDataset: {file_name}\")\n",
    "    for hp, _, final_error in results:\n",
    "        bs, fw, esl, ws = hp\n",
    "        print(f\"  batch_size={bs}, forecast_window={fw}, enc_seq_len={esl}, window_size={ws} -> Final error: {final_error:.4f}\")\n",
    "\n",
    "print(\"\\n======================================\")\n",
    "print(\"Best hyperparameter combination per dataset:\")\n",
    "for file_name, (best_hyperparams, best_error, _) in best_results_by_file.items():\n",
    "    print(f\"Dataset: {file_name} -> {best_hyperparams} with final error: {best_error:.4f}\")\n",
    "\n",
    "# ----- Plot: Create subplots (one per dataset) and plot all loss curves for that dataset. -----\n",
    "num_files = len(results_by_file)\n",
    "fig, axes = plt.subplots(num_files, 1, figsize=(10, 5*num_files))\n",
    "if num_files == 1:\n",
    "    axes = [axes]  # ensure axes is iterable\n",
    "\n",
    "for ax, (file_name, results) in zip(axes, results_by_file.items()):\n",
    "    ax.set_title(f\"Loss Curves for Dataset: {file_name}\")\n",
    "    for hp, loss_curve, _ in results:\n",
    "        bs, fw, esl, ws = hp\n",
    "        label = f\"bs={bs}, fw={fw}, esl={esl}\"\n",
    "        ax.plot(loss_curve, label=label)\n",
    "    ax.set_xlabel(\"Batch Number\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# implementing the psd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function that takes the best hyperparameters and trains the model on the entire dataset \n",
    "# then, use the trained model to predict a long timeseries of the lorenz system --> many timepoints (100000)\n",
    "# finally, evaluate the model's performance (generated timeseries) on the test data with the psd metric\n",
    "# write this psd metric function independently and test it with traindata on testdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Processing dataset\n",
      "Training with batch_size=128, forecast_window=2, enc_seq_len=6\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "src last dim (3) must match input_size (20)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[114], line 130\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m# Adjust the code to use the loaded data directly\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhyperparameter_grid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparameter_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlorenz63datatrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Training data\u001b[39;49;00m\n\u001b[0;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlorenz63datatest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Test data\u001b[39;49;00m\n\u001b[0;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_trained_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_trained_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Function to load trained models\u001b[39;49;00m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# ----- Plot Results -----\u001b[39;00m\n\u001b[0;32m    139\u001b[0m num_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(results)\n",
      "Cell \u001b[1;32mIn[114], line 58\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(hyperparameter_grid, train_data, test_data, load_trained_model, device)\u001b[0m\n\u001b[0;32m     55\u001b[0m loss_curves \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Process the dataset with the training and test data provided\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m results, best_hyperparams, best_generated_series \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameter_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_trained_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m all_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m results\n\u001b[0;32m     62\u001b[0m loss_curves[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (best_hyperparams, best_generated_series)\n",
      "Cell \u001b[1;32mIn[114], line 42\u001b[0m, in \u001b[0;36mprocess_dataset\u001b[1;34m(train_data, test_data, hyperparameter_grid, load_trained_model, device)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining with batch_size=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, forecast_window=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mforecast_window\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, enc_seq_len=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00menc_seq_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m model \u001b[38;5;241m=\u001b[39m load_trained_model()\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Load trained model\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m pse, generated_series \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_power_spectrum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m results[(batch_size, forecast_window, enc_seq_len)] \u001b[38;5;241m=\u001b[39m pse\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pse \u001b[38;5;241m<\u001b[39m best_pse:\n",
      "Cell \u001b[1;32mIn[114], line 24\u001b[0m, in \u001b[0;36mevaluate_power_spectrum\u001b[1;34m(model, train_data, test_data, device)\u001b[0m\n\u001b[0;32m     21\u001b[0m test_length \u001b[38;5;241m=\u001b[39m test_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     23\u001b[0m initial_condition \u001b[38;5;241m=\u001b[39m train_data[np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(train_data))]\n\u001b[1;32m---> 24\u001b[0m generated_series \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_time_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_condition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m pse \u001b[38;5;241m=\u001b[39m power_spectrum_error(generated_series, test_data)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pse, generated_series\n",
      "Cell \u001b[1;32mIn[114], line 14\u001b[0m, in \u001b[0;36mgenerate_time_series\u001b[1;34m(model, initial_condition, sequence_length, device)\u001b[0m\n\u001b[0;32m     11\u001b[0m         tgt_seq \u001b[38;5;241m=\u001b[39m input_seq  \u001b[38;5;66;03m# For autoregressive models, the target is usually the input itself\u001b[39;00m\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;66;03m# Pass both input and target to the model\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m         prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_seq\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# Assuming the model expects both src and tgt\u001b[39;00m\n\u001b[0;32m     16\u001b[0m         generated_series\u001b[38;5;241m.\u001b[39mappend(prediction\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(generated_series)\n",
      "File \u001b[1;32mc:\\Users\\hecht\\OneDrive - Universität Heidelberg\\Dokumente\\_Studium\\_Master\\_2. Semester\\DSML\\Final Project\\DSML_Final_Project\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hecht\\OneDrive - Universität Heidelberg\\Dokumente\\_Studium\\_Master\\_2. Semester\\DSML\\Final Project\\DSML_Final_Project\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[99], line 57\u001b[0m, in \u001b[0;36mTimeSeriesTransformer.forward\u001b[1;34m(self, src, tgt, src_mask, tgt_mask)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtgt shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtgt\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, expected last dim: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder_input_layer\u001b[38;5;241m.\u001b[39min_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Validate input dimensions\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m src\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_input_layer\u001b[38;5;241m.\u001b[39min_features, \\\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrc last dim (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) must match input_size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_input_layer\u001b[38;5;241m.\u001b[39min_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m tgt\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder_input_layer\u001b[38;5;241m.\u001b[39min_features, \\\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtgt last dim (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtgt\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) must match num_predicted_features (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder_input_layer\u001b[38;5;241m.\u001b[39min_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Encoding\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: src last dim (3) must match input_size (20)"
     ]
    }
   ],
   "source": [
    "from psd import power_spectrum_error  # Importing the PSD function\n",
    "\n",
    "def generate_time_series(model, initial_condition, sequence_length, device):\n",
    "    \"\"\"Generate a time series using the trained model.\"\"\"\n",
    "    model.eval()\n",
    "    generated_series = [initial_condition]\n",
    "    with torch.no_grad():\n",
    "        for _ in range(sequence_length - 1):\n",
    "            input_seq = torch.tensor(generated_series[-1]).unsqueeze(0).to(device)\n",
    "            \n",
    "            # The target (tgt) is typically the same as the input in autoregressive generation\n",
    "            tgt_seq = input_seq  # For autoregressive models, the target is usually the input itself\n",
    "            \n",
    "            # Pass both input and target to the model\n",
    "            prediction = model(input_seq, tgt_seq).cpu().numpy()  # Assuming the model expects both src and tgt\n",
    "            \n",
    "            generated_series.append(prediction.squeeze(0))\n",
    "            \n",
    "    return np.array(generated_series)\n",
    "\n",
    "def evaluate_power_spectrum(model, train_data, test_data, device):\n",
    "    \"\"\"Compute power spectrum distance between generated and test data.\"\"\"\n",
    "    test_length = test_data.shape[0]\n",
    "    \n",
    "    initial_condition = train_data[np.random.randint(0, len(train_data))]\n",
    "    generated_series = generate_time_series(model, initial_condition, test_length, device)\n",
    "    \n",
    "    pse = power_spectrum_error(generated_series, test_data)\n",
    "    return pse, generated_series\n",
    "\n",
    "def process_dataset(train_data, test_data, hyperparameter_grid, load_trained_model, device):\n",
    "    \"\"\"Train and evaluate models for a given dataset.\"\"\"\n",
    "    print(f\"Processing dataset\")\n",
    "\n",
    "    best_pse = float('inf')\n",
    "    best_hyperparams = None\n",
    "    best_generated_series = None\n",
    "    results = {}\n",
    "    \n",
    "    for batch_size, forecast_window, enc_seq_len, window_size in hyperparameter_grid:\n",
    "        print(f\"Training with batch_size={batch_size}, forecast_window={forecast_window}, enc_seq_len={enc_seq_len}\")\n",
    "        \n",
    "        model = load_trained_model().to(device)  # Load trained model\n",
    "        pse, generated_series = evaluate_power_spectrum(model, train_data, test_data, device)\n",
    "        results[(batch_size, forecast_window, enc_seq_len)] = pse\n",
    "        \n",
    "        if pse < best_pse:\n",
    "            best_pse = pse\n",
    "            best_hyperparams = (batch_size, forecast_window, enc_seq_len)\n",
    "            best_generated_series = generated_series\n",
    "    \n",
    "    return results, best_hyperparams, best_generated_series\n",
    "\n",
    "def train_and_evaluate(hyperparameter_grid, train_data, test_data, load_trained_model, device):\n",
    "    \"\"\"Train models and evaluate power spectrum distance for multiple datasets.\"\"\"\n",
    "    all_results = {}\n",
    "    loss_curves = {}\n",
    "\n",
    "    # Process the dataset with the training and test data provided\n",
    "    results, best_hyperparams, best_generated_series = process_dataset(\n",
    "        train_data, test_data, hyperparameter_grid, load_trained_model, device\n",
    "    )\n",
    "    all_results[\"dataset\"] = results\n",
    "    loss_curves[\"dataset\"] = (best_hyperparams, best_generated_series)\n",
    "\n",
    "    plot_loss_curves(loss_curves)\n",
    "    print_best_results(all_results, loss_curves)\n",
    "    return all_results\n",
    "\n",
    "def plot_loss_curves(loss_curves):\n",
    "    \"\"\"Plot the best loss curves for each dataset.\"\"\"\n",
    "    fig, axes = plt.subplots(len(loss_curves), 1, figsize=(10, 5 * len(loss_curves)))\n",
    "    if len(loss_curves) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for ax, (file_name, (best_hyperparams, generated_series)) in zip(axes, loss_curves.items()):\n",
    "        ax.set_title(f\"Best Loss Curve for {file_name}\")\n",
    "        ax.set_xlabel(\"Time Step\")\n",
    "        ax.set_ylabel(\"Generated vs Ground Truth\")\n",
    "        \n",
    "        batch_size, forecast_window, enc_seq_len = best_hyperparams\n",
    "        ax.plot(generated_series[:, 0], label=f\"bs={batch_size}, fw={forecast_window}, esl={enc_seq_len}\")\n",
    "        \n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def print_best_results(all_results, loss_curves):\n",
    "    \"\"\"Print best power spectrum distances per dataset.\"\"\"\n",
    "    print(\"\\nBest Power Spectrum Distance per dataset:\")\n",
    "    for file_name, (best_hyperparams, _) in loss_curves.items():\n",
    "        batch_size, forecast_window, enc_seq_len = best_hyperparams\n",
    "        pse = all_results[file_name][(batch_size, forecast_window, enc_seq_len)]\n",
    "        print(f\"{file_name}, bs={batch_size}, fw={forecast_window}, esl={enc_seq_len}: {pse:.4f}\")\n",
    "\n",
    "\n",
    "# ----- Hyperparameter Grid -----\n",
    "batch_sizes = [128]\n",
    "forecast_windows = [2, 3, 4, 5]\n",
    "enc_seq_lens = [6, 7, 8]\n",
    "# Compute window_size dynamically\n",
    "hyperparameter_grid = [\n",
    "    (batch_size, forecast_window, enc_seq_len, enc_seq_len + forecast_window)\n",
    "    for batch_size in batch_sizes\n",
    "    for forecast_window in forecast_windows\n",
    "    for enc_seq_len in enc_seq_lens\n",
    "]\n",
    "\n",
    "\n",
    "# Load the .npy files directly from the path\n",
    "lorenz63datatrain = np.load(r\"C:\\Users\\hecht\\OneDrive - Universität Heidelberg\\Dokumente\\_Studium\\_Master\\_2. Semester\\DSML\\Final Project\\DSML_Final_Project\\Traindata\\lorenz63_on0.05_train.npy\")\n",
    "lorenz96datatrain = np.load(r\"C:\\Users\\hecht\\OneDrive - Universität Heidelberg\\Dokumente\\_Studium\\_Master\\_2. Semester\\DSML\\Final Project\\DSML_Final_Project\\Traindata\\lorenz96_on0.05_train.npy\")\n",
    "\n",
    "lorenz63datatest = np.load(r\"C:\\Users\\hecht\\OneDrive - Universität Heidelberg\\Dokumente\\_Studium\\_Master\\_2. Semester\\DSML\\Final Project\\DSML_Final_Project\\Testdata\\lorenz63_test.npy\")\n",
    "lorenz96datatest = np.load(r\"C:\\Users\\hecht\\OneDrive - Universität Heidelberg\\Dokumente\\_Studium\\_Master\\_2. Semester\\DSML\\Final Project\\DSML_Final_Project\\Testdata\\lorenz96_test.npy\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ----- Train and Evaluate -----\n",
    "def load_trained_model():\n",
    "    # This function should load the trained model (e.g., after training or from a saved state)\n",
    "    # For now, it's a placeholder to return the current model being trained\n",
    "    return model\n",
    "\n",
    "\n",
    "# Adjust the code to use the loaded data directly\n",
    "results = train_and_evaluate(\n",
    "    hyperparameter_grid=hyperparameter_grid,\n",
    "    train_data=lorenz63datatrain,  # Training data\n",
    "    test_data=lorenz63datatest,    # Test data\n",
    "    load_trained_model=load_trained_model,  # Function to load trained models\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# ----- Plot Results -----\n",
    "num_files = len(results)\n",
    "fig, axes = plt.subplots(num_files, 1, figsize=(10, 5 * num_files))\n",
    "if num_files == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, (file_name, (best_hyperparams, generated_series)) in zip(axes, results.items()):\n",
    "    ax.set_title(f\"Best Loss Curve for {file_name}\")\n",
    "    ax.set_xlabel(\"Time Step\")\n",
    "    ax.set_ylabel(\"Generated vs Ground Truth\")\n",
    "\n",
    "    batch_size, forecast_window, enc_seq_len = best_hyperparams\n",
    "    ax.plot(generated_series[:, 0], label=f\"bs={batch_size}, fw={forecast_window}, esl={enc_seq_len}\")\n",
    "\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Processing file: lorenz63_on0.05_train.npy\n",
      "\n",
      "======================================\n",
      "Training with: batch_size=128, forecast_window=2, enc_seq_len=6, window_size=8\n",
      "From get_src_trg: data size = torch.Size([100000, 3])\n",
      "DataLoader size: 156\n",
      "Epoch 1/2 completed. Average loss: 1.3104\n",
      "Epoch 2/2 completed. Average loss: 0.9087\n",
      "Final error (last batch loss) for this combination: 0.7529\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "For unbatched (2-D) `query`, expected `key` and `value` to be 2-D but found 3-D and 3-D tensors respectively",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[117], line 133\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal error (last batch loss) for this combination: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinal_error\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# After training, evaluate the power spectrum\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m pse, generated_series \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_power_spectrum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# You may use different test data if available\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPower Spectrum Error (PSE): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpse\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    136\u001b[0m results_by_file[file_name]\u001b[38;5;241m.\u001b[39mappend((\n\u001b[0;32m    137\u001b[0m     (batch_size, forecast_window, enc_seq_len, window_size), \n\u001b[0;32m    138\u001b[0m     combined_loss_curve, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    141\u001b[0m     generated_series  \u001b[38;5;66;03m# Store the generated series for reference\u001b[39;00m\n\u001b[0;32m    142\u001b[0m ))\n",
      "Cell \u001b[1;32mIn[117], line 55\u001b[0m, in \u001b[0;36mevaluate_power_spectrum\u001b[1;34m(model, train_data, test_data, device)\u001b[0m\n\u001b[0;32m     53\u001b[0m test_length \u001b[38;5;241m=\u001b[39m test_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     54\u001b[0m initial_condition \u001b[38;5;241m=\u001b[39m train_data[np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(train_data))]\n\u001b[1;32m---> 55\u001b[0m generated_series \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_time_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_condition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m pse \u001b[38;5;241m=\u001b[39m power_spectrum_error(generated_series, test_data)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pse, generated_series\n",
      "Cell \u001b[1;32mIn[117], line 46\u001b[0m, in \u001b[0;36mgenerate_time_series\u001b[1;34m(model, initial_condition, sequence_length, device)\u001b[0m\n\u001b[0;32m     44\u001b[0m         input_seq \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(generated_series[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     45\u001b[0m         tgt_seq \u001b[38;5;241m=\u001b[39m input_seq  \u001b[38;5;66;03m# For autoregressive models, the target is usually the input itself\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m         prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_seq\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# Assuming the model expects both src and tgt\u001b[39;00m\n\u001b[0;32m     47\u001b[0m         generated_series\u001b[38;5;241m.\u001b[39mappend(prediction\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(generated_series)\n",
      "File \u001b[1;32mc:\\Users\\hecht\\OneDrive - Universität Heidelberg\\Dokumente\\_Studium\\_Master\\_2. Semester\\DSML\\Final Project\\DSML_Final_Project\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hecht\\OneDrive - Universität Heidelberg\\Dokumente\\_Studium\\_Master\\_2. Semester\\DSML\\Final Project\\DSML_Final_Project\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[99], line 69\u001b[0m, in \u001b[0;36mTimeSeriesTransformer.forward\u001b[1;34m(self, src, tgt, src_mask, tgt_mask)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Decoding\u001b[39;00m\n\u001b[0;32m     68\u001b[0m decoder_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder_input_layer(tgt)\n\u001b[1;32m---> 69\u001b[0m decoder_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Output mapping\u001b[39;00m\n\u001b[0;32m     72\u001b[0m decoder_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_mapping(decoder_output)\n",
      "File \u001b[1;32mc:\\Users\\hecht\\OneDrive - Universität Heidelberg\\Dokumente\\_Studium\\_Master\\_2. Semester\\DSML\\Final Project\\DSML_Final_Project\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hecht\\OneDrive - Universität Heidelberg\\Dokumente\\_Studium\\_Master\\_2. Semester\\DSML\\Final Project\\DSML_Final_Project\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\hecht\\OneDrive - Universität Heidelberg\\Dokumente\\_Studium\\_Master\\_2. Semester\\DSML\\Final Project\\DSML_Final_Project\\venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:613\u001b[0m, in \u001b[0;36mTransformerDecoder.forward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[0;32m    610\u001b[0m tgt_is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(tgt_mask, tgt_is_causal, seq_len)\n\u001b[0;32m    612\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m--> 613\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    619\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    625\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(output)\n",
      "File \u001b[1;32mc:\\Users\\hecht\\OneDrive - Universität Heidelberg\\Dokumente\\_Studium\\_Master\\_2. Semester\\DSML\\Final Project\\DSML_Final_Project\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hecht\\OneDrive - Universität Heidelberg\\Dokumente\\_Studium\\_Master\\_2. Semester\\DSML\\Final Project\\DSML_Final_Project\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\hecht\\OneDrive - Universität Heidelberg\\Dokumente\\_Studium\\_Master\\_2. Semester\\DSML\\Final Project\\DSML_Final_Project\\venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:1112\u001b[0m, in \u001b[0;36mTransformerDecoderLayer.forward\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1107\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(\n\u001b[0;32m   1108\u001b[0m         x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sa_block(x, tgt_mask, tgt_key_padding_mask, tgt_is_causal)\n\u001b[0;32m   1109\u001b[0m     )\n\u001b[0;32m   1110\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(\n\u001b[0;32m   1111\u001b[0m         x\n\u001b[1;32m-> 1112\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mha_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1113\u001b[0m \u001b[43m            \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_is_causal\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1115\u001b[0m     )\n\u001b[0;32m   1116\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm3(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\hecht\\OneDrive - Universität Heidelberg\\Dokumente\\_Studium\\_Master\\_2. Semester\\DSML\\Final Project\\DSML_Final_Project\\venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:1148\u001b[0m, in \u001b[0;36mTransformerDecoderLayer._mha_block\u001b[1;34m(self, x, mem, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_mha_block\u001b[39m(\n\u001b[0;32m   1141\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1142\u001b[0m     x: Tensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1146\u001b[0m     is_causal: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1147\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1148\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultihead_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1156\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout2(x)\n",
      "File \u001b[1;32mc:\\Users\\hecht\\OneDrive - Universität Heidelberg\\Dokumente\\_Studium\\_Master\\_2. Semester\\DSML\\Final Project\\DSML_Final_Project\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hecht\\OneDrive - Universität Heidelberg\\Dokumente\\_Studium\\_Master\\_2. Semester\\DSML\\Final Project\\DSML_Final_Project\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\hecht\\OneDrive - Universität Heidelberg\\Dokumente\\_Studium\\_Master\\_2. Semester\\DSML\\Final Project\\DSML_Final_Project\\venv\\Lib\\site-packages\\torch\\nn\\modules\\activation.py:1373\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   1347\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[0;32m   1348\u001b[0m         query,\n\u001b[0;32m   1349\u001b[0m         key,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1370\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal,\n\u001b[0;32m   1371\u001b[0m     )\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1373\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1374\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1377\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1380\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1381\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1383\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1385\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1386\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1391\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1393\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[0;32m   1395\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[1;32mc:\\Users\\hecht\\OneDrive - Universität Heidelberg\\Dokumente\\_Studium\\_Master\\_2. Semester\\DSML\\Final Project\\DSML_Final_Project\\venv\\Lib\\site-packages\\torch\\nn\\functional.py:6147\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   6116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tens_ops):\n\u001b[0;32m   6117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m   6118\u001b[0m         multi_head_attention_forward,\n\u001b[0;32m   6119\u001b[0m         tens_ops,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6144\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[0;32m   6145\u001b[0m     )\n\u001b[1;32m-> 6147\u001b[0m is_batched \u001b[38;5;241m=\u001b[39m \u001b[43m_mha_shape_check\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   6148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\n\u001b[0;32m   6149\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6151\u001b[0m \u001b[38;5;66;03m# For unbatched input, we unsqueeze at the expected batch-dim to pretend that the input\u001b[39;00m\n\u001b[0;32m   6152\u001b[0m \u001b[38;5;66;03m# is batched, run the computation and before returning squeeze the\u001b[39;00m\n\u001b[0;32m   6153\u001b[0m \u001b[38;5;66;03m# batch dimension so that the output doesn't carry this temporary batch dimension.\u001b[39;00m\n\u001b[0;32m   6154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_batched:\n\u001b[0;32m   6155\u001b[0m     \u001b[38;5;66;03m# unsqueeze if the input is unbatched\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hecht\\OneDrive - Universität Heidelberg\\Dokumente\\_Studium\\_Master\\_2. Semester\\DSML\\Final Project\\DSML_Final_Project\\venv\\Lib\\site-packages\\torch\\nn\\functional.py:5916\u001b[0m, in \u001b[0;36m_mha_shape_check\u001b[1;34m(query, key, value, key_padding_mask, attn_mask, num_heads)\u001b[0m\n\u001b[0;32m   5913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   5914\u001b[0m     \u001b[38;5;66;03m# Unbatched Inputs\u001b[39;00m\n\u001b[0;32m   5915\u001b[0m     is_batched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 5916\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m key\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m, (\n\u001b[0;32m   5917\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor unbatched (2-D) `query`, expected `key` and `value` to be 2-D\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5918\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D tensors respectively\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5919\u001b[0m     )\n\u001b[0;32m   5921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key_padding_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5922\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m key_padding_mask\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, (\n\u001b[0;32m   5923\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor unbatched (2-D) `query`, expected `key_padding_mask` to be `None` or 1-D\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5924\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey_padding_mask\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D tensor instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5925\u001b[0m         )\n",
      "\u001b[1;31mAssertionError\u001b[0m: For unbatched (2-D) `query`, expected `key` and `value` to be 2-D but found 3-D and 3-D tensors respectively"
     ]
    }
   ],
   "source": [
    "\n",
    "from psd import power_spectrum_error  # Assuming the psd import is correct\n",
    "\n",
    "# Load the training and test data for Lorenz 63 and Lorenz 96\n",
    "lorenz63datatrain = np.load(r\"C:\\Users\\hecht\\OneDrive - Universität Heidelberg\\Dokumente\\_Studium\\_Master\\_2. Semester\\DSML\\Final Project\\DSML_Final_Project\\Traindata\\lorenz63_on0.05_train.npy\")\n",
    "lorenz96datatrain = np.load(r\"C:\\Users\\hecht\\OneDrive - Universität Heidelberg\\Dokumente\\_Studium\\_Master\\_2. Semester\\DSML\\Final Project\\DSML_Final_Project\\Traindata\\lorenz96_on0.05_train.npy\")\n",
    "lorenz63datatest = np.load(r\"C:\\Users\\hecht\\OneDrive - Universität Heidelberg\\Dokumente\\_Studium\\_Master\\_2. Semester\\DSML\\Final Project\\DSML_Final_Project\\Testdata\\lorenz63_test.npy\")\n",
    "lorenz96datatest = np.load(r\"C:\\Users\\hecht\\OneDrive - Universität Heidelberg\\Dokumente\\_Studium\\_Master\\_2. Semester\\DSML\\Final Project\\DSML_Final_Project\\Testdata\\lorenz96_test.npy\")\n",
    "\n",
    "# ----- Set Up Hyperparameters -----\n",
    "batch_sizes      = [128]\n",
    "forecast_windows = [2]\n",
    "enc_seq_lens     = [6]\n",
    "hyperparameter_grid = [\n",
    "    (batch_size, forecast_window, enc_seq_len, enc_seq_len + forecast_window)\n",
    "    for batch_size in batch_sizes\n",
    "    for forecast_window in forecast_windows\n",
    "    for enc_seq_len in enc_seq_lens\n",
    "]\n",
    "\n",
    "# ----- Fixed Parameters -----\n",
    "step_size       = 5\n",
    "epochs          = 2\n",
    "batch_first     = True\n",
    "target_col_name = 'x'\n",
    "timestamp_col   = \"t\"\n",
    "exogenous_vars  = ['y', 'z']\n",
    "input_variables = [target_col_name] + exogenous_vars\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "results_by_file = {}\n",
    "best_results_by_file = {}\n",
    "\n",
    "# ----- Model Generation -----\n",
    "def generate_time_series(model, initial_condition, sequence_length, device):\n",
    "    \"\"\"Generate a time series using the trained model.\"\"\"\n",
    "    model.eval()\n",
    "    generated_series = [initial_condition]\n",
    "    with torch.no_grad():\n",
    "        for _ in range(sequence_length - 1):\n",
    "            input_seq = torch.tensor(generated_series[-1]).unsqueeze(0).to(device)\n",
    "            tgt_seq = input_seq  # For autoregressive models, the target is usually the input itself\n",
    "            prediction = model(input_seq, tgt_seq).cpu().numpy()  # Assuming the model expects both src and tgt\n",
    "            generated_series.append(prediction.squeeze(0))\n",
    "            \n",
    "    return np.array(generated_series)\n",
    "\n",
    "def evaluate_power_spectrum(model, train_data, test_data, device):\n",
    "    \"\"\"Compute power spectrum distance between generated and test data.\"\"\"\n",
    "    test_length = test_data.shape[0]  # Length of the test data\n",
    "    initial_condition = train_data[np.random.randint(0, len(train_data))]  # Random starting point from training data\n",
    "    generated_series = generate_time_series(model, initial_condition, test_length, device)  # Generate data using the model\n",
    "    \n",
    "    # Compute power spectrum error\n",
    "    pse = power_spectrum_error(generated_series, test_data)  # Compare the generated series with the ground truth (test_data)\n",
    "    return pse, generated_series\n",
    "\n",
    "# ----- Dataset and Model Training -----\n",
    "\n",
    "# Train and evaluate for Lorenz 63 and Lorenz 96 datasets\n",
    "for data, data_test, file_name in zip(\n",
    "    [(lorenz63datatrain, lorenz63datatest, \"lorenz63\")],\n",
    "    [(lorenz96datatrain, lorenz96datatest, \"lorenz96\")]\n",
    "):\n",
    "    # Use the entire training set and the test set for evaluation\n",
    "    train_data, test_data = data  # Train data is used for training, test data only for evaluation\n",
    "\n",
    "    input_size = train_data.shape[1]\n",
    "    results_by_file[file_name] = []\n",
    "    best_error = float('inf')\n",
    "    best_hyperparams = None\n",
    "    best_loss_curve = None\n",
    "\n",
    "    for batch_size, forecast_window, enc_seq_len, window_size in hyperparameter_grid:\n",
    "        print(f\"\\nTraining with: batch_size={batch_size}, forecast_window={forecast_window}, enc_seq_len={enc_seq_len}, window_size={window_size}\")\n",
    "        \n",
    "        # Create Dataset and DataLoader\n",
    "        training_indices = get_indices_entire_sequence(train_data, window_size, step_size)\n",
    "        if len(training_indices) == 0:\n",
    "            print(f\"No valid training indices found in {file_name} for window_size={window_size}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        training_data = TransformerDataset(\n",
    "            data=torch.tensor(train_data).float(),\n",
    "            indices=training_indices,\n",
    "            enc_seq_len=enc_seq_len,\n",
    "            dec_seq_len=forecast_window,\n",
    "            target_seq_len=forecast_window\n",
    "        )\n",
    "        training_dataloader = DataLoader(training_data, batch_size=batch_size, drop_last=True)\n",
    "\n",
    "        model = TimeSeriesTransformer(\n",
    "            input_size=input_size,\n",
    "            dec_seq_len=forecast_window,\n",
    "            batch_first=batch_first,\n",
    "            num_predicted_features=input_size\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "        criterion = torch.nn.MSELoss()\n",
    "\n",
    "        combined_loss_curve = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            epoch_losses = []\n",
    "            for src, tgt, tgt_y in training_dataloader:\n",
    "                src = src.to(device)\n",
    "                tgt = tgt.to(device)\n",
    "                tgt_y = tgt_y.to(device)\n",
    "\n",
    "                mask_enc = generate_square_subsequent_mask(forecast_window, enc_seq_len).to(device)\n",
    "                mask_dec = generate_square_subsequent_mask(forecast_window, forecast_window).to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                prediction = model(src, tgt, mask_enc, mask_dec)\n",
    "                loss = criterion(tgt_y, prediction)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_losses.append(loss.item())\n",
    "                combined_loss_curve.append(loss.item())\n",
    "\n",
    "            avg_epoch_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "            print(f\"Epoch {epoch+1}/{epochs} completed. Average loss: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "        final_error = combined_loss_curve[-1]\n",
    "        print(f\"Final error for this combination: {final_error:.4f}\")\n",
    "\n",
    "        results_by_file[file_name].append(((batch_size, forecast_window, enc_seq_len, window_size), combined_loss_curve, final_error))\n",
    "\n",
    "        if final_error < best_error:\n",
    "            best_error = final_error\n",
    "            best_hyperparams = {\n",
    "                'batch_size': batch_size,\n",
    "                'forecast_window': forecast_window,\n",
    "                'enc_seq_len': enc_seq_len,\n",
    "                'window_size': window_size\n",
    "            }\n",
    "            best_loss_curve = combined_loss_curve\n",
    "\n",
    "    best_results_by_file[file_name] = (best_hyperparams, best_error, best_loss_curve)\n",
    "\n",
    "    # Evaluate power spectrum on test data after training\n",
    "    pse, generated_series = evaluate_power_spectrum(model, train_data, test_data, device)\n",
    "    print(f\"Power Spectrum Error (PSE): {pse:.4f}\")\n",
    "\n",
    "    # Add results to dictionary\n",
    "    results_by_file[file_name].append((\n",
    "        best_hyperparams,\n",
    "        best_error,\n",
    "        best_loss_curve,\n",
    "        pse  # Add PSE to the results for further analysis\n",
    "    ))\n",
    "\n",
    "# Display the results\n",
    "print(\"\\n======================================\")\n",
    "for file_name, results in results_by_file.items():\n",
    "    print(f\"Dataset: {file_name}\")\n",
    "    for hp, _, _, pse in results:\n",
    "        print(f\"Best Hyperparameters: {hp} -> Power Spectrum Error (PSE): {pse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
